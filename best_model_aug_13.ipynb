{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ary2260/Work/UK_Research/principal-odor-map'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (/home/ary2260/miniconda3/envs/odor_pom/lib/python3.9/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/home/ary2260/miniconda3/envs/odor_pom/lib/python3.9/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "from principal_odor_map.feat.graph_featurizer import GraphFeaturizer, GraphConvConstants\n",
    "from principal_odor_map.utils.data_utils import get_class_imbalance_ratio\n",
    "from principal_odor_map.models.mpnn_pom import MPNNPOMModel\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of tasks:  138\n"
     ]
    }
   ],
   "source": [
    "TASKS = [\n",
    "'alcoholic', 'aldehydic', 'alliaceous', 'almond', 'amber', 'animal',\n",
    "'anisic', 'apple', 'apricot', 'aromatic', 'balsamic', 'banana', 'beefy',\n",
    "'bergamot', 'berry', 'bitter', 'black currant', 'brandy', 'burnt',\n",
    "'buttery', 'cabbage', 'camphoreous', 'caramellic', 'cedar', 'celery',\n",
    "'chamomile', 'cheesy', 'cherry', 'chocolate', 'cinnamon', 'citrus', 'clean',\n",
    "'clove', 'cocoa', 'coconut', 'coffee', 'cognac', 'cooked', 'cooling',\n",
    "'cortex', 'coumarinic', 'creamy', 'cucumber', 'dairy', 'dry', 'earthy',\n",
    "'ethereal', 'fatty', 'fermented', 'fishy', 'floral', 'fresh', 'fruit skin',\n",
    "'fruity', 'garlic', 'gassy', 'geranium', 'grape', 'grapefruit', 'grassy',\n",
    "'green', 'hawthorn', 'hay', 'hazelnut', 'herbal', 'honey', 'hyacinth',\n",
    "'jasmin', 'juicy', 'ketonic', 'lactonic', 'lavender', 'leafy', 'leathery',\n",
    "'lemon', 'lily', 'malty', 'meaty', 'medicinal', 'melon', 'metallic',\n",
    "'milky', 'mint', 'muguet', 'mushroom', 'musk', 'musty', 'natural', 'nutty',\n",
    "'odorless', 'oily', 'onion', 'orange', 'orangeflower', 'orris', 'ozone',\n",
    "'peach', 'pear', 'phenolic', 'pine', 'pineapple', 'plum', 'popcorn',\n",
    "'potato', 'powdery', 'pungent', 'radish', 'raspberry', 'ripe', 'roasted',\n",
    "'rose', 'rummy', 'sandalwood', 'savory', 'sharp', 'smoky', 'soapy',\n",
    "'solvent', 'sour', 'spicy', 'strawberry', 'sulfurous', 'sweaty', 'sweet',\n",
    "'tea', 'terpenic', 'tobacco', 'tomato', 'tropical', 'vanilla', 'vegetable',\n",
    "'vetiver', 'violet', 'warm', 'waxy', 'weedy', 'winey', 'woody'\n",
    "]\n",
    "print(\"No of tasks: \", len(TASKS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "\n",
    "featurizer = GraphFeaturizer()\n",
    "smiles_field = 'nonStereoSMILES'\n",
    "loader = dc.data.CSVLoader(tasks=TASKS,\n",
    "                   feature_field=smiles_field,\n",
    "                   featurizer=featurizer)\n",
    "input_file = \\\n",
    "    'principal_odor_map/data/curated_datasets/curated_GS_LF_merged_4983.csv'\n",
    "dataset = loader.create_dataset(inputs=[input_file])\n",
    "n_tasks = len(dataset.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4983"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train valid test splits\n",
    "\n",
    "randomstratifiedsplitter = dc.splits.RandomStratifiedSplitter()\n",
    "train_dataset, test_dataset, valid_dataset = randomstratifiedsplitter.train_valid_test_split(dataset, frac_train = 0.8, frac_valid = 0.1, frac_test = 0.1, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset:  3999\n",
      "valid_dataset:  498\n",
      "test_dataset:  486\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataset: \", len(train_dataset))\n",
    "print(\"valid_dataset: \", len(valid_dataset))\n",
    "print(\"test_dataset: \", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratios = get_class_imbalance_ratio(train_dataset)\n",
    "assert len(train_ratios) == n_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = ExponentialDecay(initial_rate=0.001, decay_rate=0.5, decay_steps=32*15, staircase=True)\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "\n",
    "model = MPNNPOMModel(n_tasks = n_tasks,\n",
    "                            batch_size=128,\n",
    "                            learning_rate=learning_rate,\n",
    "                            class_imbalance_ratio = train_ratios,\n",
    "                            loss_aggr_type = 'sum',\n",
    "                            node_out_feats = 100,\n",
    "                            edge_hidden_feats = 75,\n",
    "                            edge_out_feats = 100,\n",
    "                            num_step_message_passing = 5,\n",
    "                            mpnn_residual = True,\n",
    "                            message_aggregator_type = 'sum',\n",
    "                            mode = 'classification',\n",
    "                            number_atom_features = GraphConvConstants.ATOM_FDIM,\n",
    "                            number_bond_features = GraphConvConstants.BOND_FDIM,\n",
    "                            n_classes = 1,\n",
    "                            readout_type = 'set2set',\n",
    "                            num_step_set2set = 3,\n",
    "                            num_layer_set2set = 2,\n",
    "                            ffn_hidden_list= [392, 392],\n",
    "                            ffn_embeddings = 256,\n",
    "                            ffn_activation = 'relu',\n",
    "                            ffn_dropout_p = 0.12,\n",
    "                            ffn_dropout_at_input_no_act = False,\n",
    "                            weight_decay = 1e-5,\n",
    "                            self_loop = False,\n",
    "                            optimizer_name = 'adam',\n",
    "                            log_frequency = 32,\n",
    "                            model_dir = './experiments',\n",
    "                            device_name='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/25 ; loss = 3.956946849822998; train_scores = 0.6542137034939426; valid_scores = 0.6402875508183986\n",
      "epoch 2/25 ; loss = 3.211834192276001; train_scores = 0.6992340218882602; valid_scores = 0.7019658280550022\n",
      "epoch 3/25 ; loss = 2.9988291263580322; train_scores = 0.7919371141506792; valid_scores = 0.7854665469055684\n",
      "epoch 4/25 ; loss = 2.880225658416748; train_scores = 0.797638133395541; valid_scores = 0.7866035357833681\n",
      "epoch 5/25 ; loss = 2.8053064346313477; train_scores = 0.8175717378172938; valid_scores = 0.8047920131683365\n",
      "epoch 6/25 ; loss = 2.751612901687622; train_scores = 0.8407297282376259; valid_scores = 0.8295796640250793\n",
      "epoch 7/25 ; loss = 2.71565580368042; train_scores = 0.8530435156011746; valid_scores = 0.8327432306967744\n",
      "epoch 8/25 ; loss = 2.6672356128692627; train_scores = 0.8482816886213209; valid_scores = 0.8322583478044153\n",
      "epoch 9/25 ; loss = 2.6258034706115723; train_scores = 0.8556105911186301; valid_scores = 0.8370115321789384\n",
      "epoch 10/25 ; loss = 2.5914711952209473; train_scores = 0.8690651791733417; valid_scores = 0.8474930671553236\n",
      "epoch 11/25 ; loss = 2.5514957904815674; train_scores = 0.8699545878217173; valid_scores = 0.8431076138972575\n",
      "epoch 12/25 ; loss = 2.5455145835876465; train_scores = 0.8642366935108239; valid_scores = 0.8398113319834557\n",
      "epoch 13/25 ; loss = 2.5207860469818115; train_scores = 0.8740013414654774; valid_scores = 0.851818120266075\n",
      "epoch 14/25 ; loss = 2.487062454223633; train_scores = 0.8852345514237199; valid_scores = 0.8597377949731534\n",
      "epoch 15/25 ; loss = 2.4721200466156006; train_scores = 0.8841592380253591; valid_scores = 0.8559050687412539\n",
      "epoch 16/25 ; loss = 2.458470106124878; train_scores = 0.8899150106794648; valid_scores = 0.8581040729193485\n",
      "epoch 17/25 ; loss = 2.4133427143096924; train_scores = 0.8826743904330184; valid_scores = 0.8492334207594364\n",
      "epoch 18/25 ; loss = 2.427197217941284; train_scores = 0.8947783249542507; valid_scores = 0.8616338584040102\n",
      "epoch 19/25 ; loss = 2.3947582244873047; train_scores = 0.8983132302355243; valid_scores = 0.8635482669743073\n",
      "epoch 20/25 ; loss = 2.3684606552124023; train_scores = 0.8994504738505221; valid_scores = 0.864847253284405\n",
      "epoch 21/25 ; loss = 2.3522536754608154; train_scores = 0.9016942135241026; valid_scores = 0.8642818539262123\n",
      "epoch 22/25 ; loss = 2.3420963287353516; train_scores = 0.8924039481017781; valid_scores = 0.8571433959164667\n",
      "epoch 23/25 ; loss = 2.335240125656128; train_scores = 0.9020302539647173; valid_scores = 0.8677739792037751\n",
      "epoch 24/25 ; loss = 2.3181118965148926; train_scores = 0.9013940136675256; valid_scores = 0.8639427602127625\n",
      "epoch 25/25 ; loss = 2.2908754348754883; train_scores = 0.9050996819525793; valid_scores = 0.8644981726587566\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "for epoch in range(1, nb_epoch+1):\n",
    "        loss = model.fit(\n",
    "              train_dataset,\n",
    "              nb_epoch=1,\n",
    "              max_checkpoints_to_keep=1,\n",
    "              deterministic=False,\n",
    "              restore=epoch>1)\n",
    "        train_scores = model.evaluate(train_dataset, [metric])['roc_auc_score']\n",
    "        valid_scores = model.evaluate(valid_dataset, [metric])['roc_auc_score']\n",
    "        print(f\"epoch {epoch}/{nb_epoch} ; loss = {loss}; train_scores = {train_scores}; valid_scores = {valid_scores}\")\n",
    "model.save_checkpoint()\n",
    "end_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_taken:  0:02:16.473233\n",
      "test_score:  0.8596834200627202\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(test_dataset, [metric])['roc_auc_score']\n",
    "print(\"time_taken: \", str(end_time-start_time))\n",
    "print(\"test_score: \", test_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odor_pom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
