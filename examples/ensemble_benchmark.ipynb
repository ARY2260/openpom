{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/home/ary2260/miniconda3/envs/testenv/lib/python3.9/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "from openpom.feat.graph_featurizer import GraphFeaturizer, GraphConvConstants\n",
    "from openpom.utils.data_utils import get_class_imbalance_ratio, IterativeStratifiedSplitter\n",
    "from openpom.models.mpnn_pom import MPNNPOMModel\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of tasks:  138\n"
     ]
    }
   ],
   "source": [
    "TASKS = [\n",
    "'alcoholic', 'aldehydic', 'alliaceous', 'almond', 'amber', 'animal',\n",
    "'anisic', 'apple', 'apricot', 'aromatic', 'balsamic', 'banana', 'beefy',\n",
    "'bergamot', 'berry', 'bitter', 'black currant', 'brandy', 'burnt',\n",
    "'buttery', 'cabbage', 'camphoreous', 'caramellic', 'cedar', 'celery',\n",
    "'chamomile', 'cheesy', 'cherry', 'chocolate', 'cinnamon', 'citrus', 'clean',\n",
    "'clove', 'cocoa', 'coconut', 'coffee', 'cognac', 'cooked', 'cooling',\n",
    "'cortex', 'coumarinic', 'creamy', 'cucumber', 'dairy', 'dry', 'earthy',\n",
    "'ethereal', 'fatty', 'fermented', 'fishy', 'floral', 'fresh', 'fruit skin',\n",
    "'fruity', 'garlic', 'gassy', 'geranium', 'grape', 'grapefruit', 'grassy',\n",
    "'green', 'hawthorn', 'hay', 'hazelnut', 'herbal', 'honey', 'hyacinth',\n",
    "'jasmin', 'juicy', 'ketonic', 'lactonic', 'lavender', 'leafy', 'leathery',\n",
    "'lemon', 'lily', 'malty', 'meaty', 'medicinal', 'melon', 'metallic',\n",
    "'milky', 'mint', 'muguet', 'mushroom', 'musk', 'musty', 'natural', 'nutty',\n",
    "'odorless', 'oily', 'onion', 'orange', 'orangeflower', 'orris', 'ozone',\n",
    "'peach', 'pear', 'phenolic', 'pine', 'pineapple', 'plum', 'popcorn',\n",
    "'potato', 'powdery', 'pungent', 'radish', 'raspberry', 'ripe', 'roasted',\n",
    "'rose', 'rummy', 'sandalwood', 'savory', 'sharp', 'smoky', 'soapy',\n",
    "'solvent', 'sour', 'spicy', 'strawberry', 'sulfurous', 'sweaty', 'sweet',\n",
    "'tea', 'terpenic', 'tobacco', 'tomato', 'tropical', 'vanilla', 'vegetable',\n",
    "'vetiver', 'violet', 'warm', 'waxy', 'weedy', 'winey', 'woody'\n",
    "]\n",
    "\n",
    "print(\"No of tasks: \", len(TASKS))\n",
    "n_tasks = len(TASKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset:  3989\n",
      "test_dataset:  994\n"
     ]
    }
   ],
   "source": [
    "# # uncomment and run if no splits saved yet\n",
    "\n",
    "# # download curated dataset\n",
    "# !wget https://raw.githubusercontent.com/ARY2260/openpom/main/openpom/data/curated_datasets/curated_GS_LF_merged_4983.csv\n",
    "\n",
    "# # The curated dataset can also found at `openpom/data/curated_datasets/curated_GS_LF_merged_4983.csv` in the repo.\n",
    "\n",
    "# input_file = 'curated_GS_LF_merged_4983.csv' # or new downloaded file path\n",
    "\n",
    "# # get dataset\n",
    "\n",
    "# featurizer = GraphFeaturizer()\n",
    "# smiles_field = 'nonStereoSMILES'\n",
    "# loader = dc.data.CSVLoader(tasks=TASKS,\n",
    "#                    feature_field=smiles_field,\n",
    "#                    featurizer=featurizer)\n",
    "# dataset = loader.create_dataset(inputs=[input_file])\n",
    "# n_tasks = len(dataset.tasks)\n",
    "\n",
    "# # get train valid test splits\n",
    "# splitter = IterativeStratifiedSplitter(order=2)\n",
    "# train_dataset, test_dataset = splitter.train_test_split(dataset, frac_train=0.8, train_dir='./splits/train_data', test_dir='./splits/test_data')\n",
    "\n",
    "# print(\"train_dataset: \", len(train_dataset))\n",
    "# print(\"test_dataset: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset:  3989\n",
      "test_dataset:  994\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dc.data.DiskDataset('./splits/train_data')\n",
    "test_dataset = dc.data.DiskDataset('./splits/test_data')\n",
    "print(\"train_dataset: \", len(train_dataset))\n",
    "print(\"test_dataset: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratios = get_class_imbalance_ratio(train_dataset)\n",
    "assert len(train_ratios) == n_tasks\n",
    "\n",
    "# learning_rate = 0.001\n",
    "learning_rate = dc.models.optimizers.ExponentialDecay(initial_rate=0.001, decay_rate=0.5, decay_steps=32*20, staircase=True)\n",
    "\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if detailed log is needed\n",
    "\n",
    "# import logging\n",
    "\n",
    "# logger = logging.getLogger(__name__)\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of models in the ensemble\n",
    "n_models = 1\n",
    "\n",
    "# no of epochs each model is trained for\n",
    "nb_epoch = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [07:02<00:00, 422.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.590301275253296; train_scores = 0.9566895671119533; test_scores = 0.922809497309699; time_taken = 0:06:55.830029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n_models)):\n",
    "    model = MPNNPOMModel(n_tasks = n_tasks,\n",
    "                            batch_size=128,\n",
    "                            learning_rate=learning_rate,\n",
    "                            class_imbalance_ratio = train_ratios,\n",
    "                            loss_aggr_type = 'sum',\n",
    "                            node_out_feats = 100,\n",
    "                            edge_hidden_feats = 75,\n",
    "                            edge_out_feats = 100,\n",
    "                            num_step_message_passing = 5,\n",
    "                            mpnn_residual = True,\n",
    "                            message_aggregator_type = 'sum',\n",
    "                            mode = 'classification',\n",
    "                            number_atom_features = GraphConvConstants.ATOM_FDIM,\n",
    "                            number_bond_features = GraphConvConstants.BOND_FDIM,\n",
    "                            n_classes = 1,\n",
    "                            readout_type = 'set2set',\n",
    "                            num_step_set2set = 3,\n",
    "                            num_layer_set2set = 2,\n",
    "                            ffn_hidden_list= [392, 392],\n",
    "                            ffn_embeddings = 256,\n",
    "                            ffn_activation = 'relu',\n",
    "                            ffn_dropout_p = 0.12,\n",
    "                            ffn_dropout_at_input_no_act = False,\n",
    "                            weight_decay = 1e-5,\n",
    "                            self_loop = False,\n",
    "                            optimizer_name = 'adam',\n",
    "                            log_frequency = 32,\n",
    "                            model_dir = f'./ensemble_models/experiments_{i+1}',\n",
    "                            device_name='cuda')\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # fit model\n",
    "    loss = model.fit(\n",
    "          train_dataset,\n",
    "          nb_epoch=nb_epoch,\n",
    "          max_checkpoints_to_keep=1,\n",
    "          deterministic=False,\n",
    "          restore=False)\n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    train_scores = model.evaluate(train_dataset, [metric])['roc_auc_score']\n",
    "    test_scores = model.evaluate(test_dataset, [metric])['roc_auc_score']\n",
    "    print(f\"loss = {loss}; train_scores = {train_scores}; test_scores = {test_scores}; time_taken = {str(end_time-start_time)}\")\n",
    "    model.save_checkpoint() # saves final checkpoint => `checkpoint2.pt`\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get test score from the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average ensemble score:  0.9228094973096989\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "list_preds = []\n",
    "for i in range(n_models):\n",
    "    model = MPNNPOMModel(n_tasks = n_tasks,\n",
    "                            batch_size=128,\n",
    "                            learning_rate=learning_rate,\n",
    "                            class_imbalance_ratio = train_ratios,\n",
    "                            loss_aggr_type = 'sum',\n",
    "                            node_out_feats = 100,\n",
    "                            edge_hidden_feats = 75,\n",
    "                            edge_out_feats = 100,\n",
    "                            num_step_message_passing = 5,\n",
    "                            mpnn_residual = True,\n",
    "                            message_aggregator_type = 'sum',\n",
    "                            mode = 'classification',\n",
    "                            number_atom_features = GraphConvConstants.ATOM_FDIM,\n",
    "                            number_bond_features = GraphConvConstants.BOND_FDIM,\n",
    "                            n_classes = 1,\n",
    "                            readout_type = 'set2set',\n",
    "                            num_step_set2set = 3,\n",
    "                            num_layer_set2set = 2,\n",
    "                            ffn_hidden_list= [392, 392],\n",
    "                            ffn_embeddings = 256,\n",
    "                            ffn_activation = 'relu',\n",
    "                            ffn_dropout_p = 0.12,\n",
    "                            ffn_dropout_at_input_no_act = False,\n",
    "                            weight_decay = 1e-5,\n",
    "                            self_loop = False,\n",
    "                            optimizer_name = 'adam',\n",
    "                            log_frequency = 32,\n",
    "                            model_dir = f'./ensemble_models/experiments_{i+1}',\n",
    "                            device_name='cuda')\n",
    "    model.restore(f\"./ensemble_models/experiments_{i+1}/checkpoint2.pt\")\n",
    "    # test_scores = model.evaluate(test_dataset, [metric])['roc_auc_score']\n",
    "    # print(\"test_score: \", test_scores)\n",
    "    preds = model.predict(test_dataset)\n",
    "    list_preds.append(preds)\n",
    "\n",
    "preds_arr = np.asarray(list_preds)\n",
    "ensemble_preds = np.mean(preds_arr, axis=0)\n",
    "print(\"average ensemble score: \", roc_auc_score(test_dataset.y, ensemble_preds, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
