{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example script for training MPNN-POM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "from openpom.feat.graph_featurizer import GraphFeaturizer, GraphConvConstants\n",
    "from openpom.utils.data_utils import get_class_imbalance_ratio, IterativeStratifiedSplitter\n",
    "from openpom.models.mpnn_pom import MPNNPOMModel\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = [\n",
    "'alcoholic', 'aldehydic', 'alliaceous', 'almond', 'amber', 'animal',\n",
    "'anisic', 'apple', 'apricot', 'aromatic', 'balsamic', 'banana', 'beefy',\n",
    "'bergamot', 'berry', 'bitter', 'black currant', 'brandy', 'burnt',\n",
    "'buttery', 'cabbage', 'camphoreous', 'caramellic', 'cedar', 'celery',\n",
    "'chamomile', 'cheesy', 'cherry', 'chocolate', 'cinnamon', 'citrus', 'clean',\n",
    "'clove', 'cocoa', 'coconut', 'coffee', 'cognac', 'cooked', 'cooling',\n",
    "'cortex', 'coumarinic', 'creamy', 'cucumber', 'dairy', 'dry', 'earthy',\n",
    "'ethereal', 'fatty', 'fermented', 'fishy', 'floral', 'fresh', 'fruit skin',\n",
    "'fruity', 'garlic', 'gassy', 'geranium', 'grape', 'grapefruit', 'grassy',\n",
    "'green', 'hawthorn', 'hay', 'hazelnut', 'herbal', 'honey', 'hyacinth',\n",
    "'jasmin', 'juicy', 'ketonic', 'lactonic', 'lavender', 'leafy', 'leathery',\n",
    "'lemon', 'lily', 'malty', 'meaty', 'medicinal', 'melon', 'metallic',\n",
    "'milky', 'mint', 'muguet', 'mushroom', 'musk', 'musty', 'natural', 'nutty',\n",
    "'odorless', 'oily', 'onion', 'orange', 'orangeflower', 'orris', 'ozone',\n",
    "'peach', 'pear', 'phenolic', 'pine', 'pineapple', 'plum', 'popcorn',\n",
    "'potato', 'powdery', 'pungent', 'radish', 'raspberry', 'ripe', 'roasted',\n",
    "'rose', 'rummy', 'sandalwood', 'savory', 'sharp', 'smoky', 'soapy',\n",
    "'solvent', 'sour', 'spicy', 'strawberry', 'sulfurous', 'sweaty', 'sweet',\n",
    "'tea', 'terpenic', 'tobacco', 'tomato', 'tropical', 'vanilla', 'vegetable',\n",
    "'vetiver', 'violet', 'warm', 'waxy', 'weedy', 'winey', 'woody'\n",
    "]\n",
    "print(\"No of tasks: \", len(TASKS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download curated dataset\n",
    "!wget https://raw.githubusercontent.com/ARY2260/openpom/main/openpom/data/curated_datasets/curated_GS_LF_merged_4983.csv\n",
    "\n",
    "# The curated dataset can also found at `openpom/data/curated_datasets/curated_GS_LF_merged_4983.csv` in the repo.\n",
    "\n",
    "input_file = 'curated_GS_LF_merged_4983.csv' # or new downloaded file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "\n",
    "featurizer = GraphFeaturizer()\n",
    "smiles_field = 'nonStereoSMILES'\n",
    "loader = dc.data.CSVLoader(tasks=TASKS,\n",
    "                   feature_field=smiles_field,\n",
    "                   featurizer=featurizer)\n",
    "dataset = loader.create_dataset(inputs=[input_file])\n",
    "n_tasks = len(dataset.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check total datapoints per odor\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "for i in range(138):\n",
    "    datapoint = {'odor': TASKS[i], \"count\": dataset.y[:,i].sum()}\n",
    "    data.append(datapoint)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.sort_values(by='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train valid test splits (deepchem version)\n",
    "\n",
    "# randomstratifiedsplitter = dc.splits.RandomStratifiedSplitter()\n",
    "# train_dataset, test_dataset, valid_dataset = randomstratifiedsplitter.train_valid_test_split(dataset, frac_train = 0.8, frac_valid = 0.1, frac_test = 0.1, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train valid test splits (paper version)\n",
    "\n",
    "splitter = IterativeStratifiedSplitter(order=2)\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset, frac_train=0.8, frac_valid = 0.1, frac_test = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for data-leakage\n",
    "\n",
    "assert len(set(train_dataset.ids).intersection(set(valid_dataset.ids))) == 0\n",
    "assert len(set(train_dataset.ids).intersection(set(test_dataset.ids))) == 0\n",
    "assert len(set(valid_dataset.ids).intersection(set(test_dataset.ids))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_dataset: \", len(train_dataset))\n",
    "print(\"valid_dataset: \", len(valid_dataset))\n",
    "print(\"test_dataset: \", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratios = get_class_imbalance_ratio(train_dataset)\n",
    "assert len(train_ratios) == n_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = dc.models.optimizers.ExponentialDecay(initial_rate=0.001, decay_rate=0.5, decay_steps=32*15, staircase=True)\n",
    "# learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "\n",
    "model = MPNNPOMModel(n_tasks = n_tasks,\n",
    "                            batch_size=128,\n",
    "                            learning_rate=learning_rate,\n",
    "                            class_imbalance_ratio = train_ratios,\n",
    "                            loss_aggr_type = 'sum',\n",
    "                            node_out_feats = 100,\n",
    "                            edge_hidden_feats = 75,\n",
    "                            edge_out_feats = 100,\n",
    "                            num_step_message_passing = 5,\n",
    "                            mpnn_residual = True,\n",
    "                            message_aggregator_type = 'sum',\n",
    "                            mode = 'classification',\n",
    "                            number_atom_features = GraphConvConstants.ATOM_FDIM,\n",
    "                            number_bond_features = GraphConvConstants.BOND_FDIM,\n",
    "                            n_classes = 1,\n",
    "                            readout_type = 'set2set',\n",
    "                            num_step_set2set = 3,\n",
    "                            num_layer_set2set = 2,\n",
    "                            ffn_hidden_list= [392, 392],\n",
    "                            ffn_embeddings = 256,\n",
    "                            ffn_activation = 'relu',\n",
    "                            ffn_dropout_p = 0.12,\n",
    "                            ffn_dropout_at_input_no_act = False,\n",
    "                            weight_decay = 1e-5,\n",
    "                            self_loop = False,\n",
    "                            optimizer_name = 'adam',\n",
    "                            log_frequency = 32,\n",
    "                            model_dir = './examples/experiments',\n",
    "                            device_name='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "for epoch in range(1, nb_epoch+1):\n",
    "        loss = model.fit(\n",
    "              train_dataset,\n",
    "              nb_epoch=1,\n",
    "              max_checkpoints_to_keep=1,\n",
    "              deterministic=False,\n",
    "              restore=epoch>1)\n",
    "        train_scores = model.evaluate(train_dataset, [metric])['roc_auc_score']\n",
    "        valid_scores = model.evaluate(valid_dataset, [metric])['roc_auc_score']\n",
    "        print(f\"epoch {epoch}/{nb_epoch} ; loss = {loss}; train_scores = {train_scores}; valid_scores = {valid_scores}\")\n",
    "model.save_checkpoint()\n",
    "end_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = model.evaluate(test_dataset, [metric])['roc_auc_score']\n",
    "print(\"time_taken: \", str(end_time-start_time))\n",
    "print(\"test_score: \", test_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_pom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
